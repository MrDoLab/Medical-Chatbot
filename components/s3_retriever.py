# components/s3_retriever.py
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
import boto3
import json
import numpy as np
import time
import logging

logger = logging.getLogger(__name__)
boto3.setup_default_session(region_name='us-east-2')

class S3Retriever:
    """S3 ê¸°ë°˜ ì„ë² ë”© ê²€ìƒ‰ ë‹´ë‹¹ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 bucket_name="aws-medical-chatbot",
                 search_function="arn:aws:lambda:us-east-2:481371222694:function:medical-embedding-search",
                 region_name="us-east-2", 
                 enabled=True):
        """
        S3 ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        
        Args:
            bucket_name: S3 ë²„í‚· ì´ë¦„
            search_function: ì„ë² ë”© ê²€ìƒ‰ Lambda í•¨ìˆ˜ ì´ë¦„
            enabled: S3 ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€
        """
        self.s3 = boto3.client('s3')
        self.lambda_client = boto3.client('lambda')
        self.bucket_name = bucket_name
        self.search_function = search_function
        self.enabled = enabled
        
        # ê²€ìƒ‰ í†µê³„
        self.search_stats = {
            "total_searches": 0,
            "successful_searches": 0,
            "failed_searches": 0,
            "total_documents_found": 0,
            "average_response_time": 0.0
        }
        
        # ì´ˆê¸°í™” ë¡œê·¸
        status = "í™œì„±í™”" if enabled else "ë¹„í™œì„±í™”"
        print(f"ğŸ” S3 ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ (ìƒíƒœ: {status})")
        print(f"   ğŸ“¦ ë²„í‚·: {bucket_name}")
        print(f"   ğŸ” ê²€ìƒ‰ í•¨ìˆ˜: {search_function}")
    
    def retrieve_documents(self, question: str, k: int = 5, 
                          category_filter: Optional[str] = None, 
                          folder_filter: Optional[str] = None) -> List[Document]:
        """S3 ì„ë² ë”© ì‹œìŠ¤í…œì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        
        # ë¹„í™œì„±í™” ìƒíƒœë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not self.enabled:
            print("  âš ï¸ S3 ë¦¬íŠ¸ë¦¬ë²„ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return []
        
        print(f"==== [S3 SEARCH: {question[:50]}...] ====")
        start_time = time.time()
        
        try:
            # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° êµ¬ì„±
            payload = {
                'query': question,
                'top_k': k,
                'use_cache': True
            }
            
            # í•„í„° ì¶”ê°€ (ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
            if category_filter:
                payload['category'] = category_filter
                print(f"  ğŸ” ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©: {category_filter}")
            
            if folder_filter:
                payload['folder'] = folder_filter
                print(f"  ğŸ” í´ë” í•„í„° ì ìš©: {folder_filter}")
            
            # Lambda í•¨ìˆ˜ í˜¸ì¶œ
            print(f"  ğŸ”„ Lambda í•¨ìˆ˜ í˜¸ì¶œ: {self.search_function}")
            response = self.lambda_client.invoke(
                FunctionName=self.search_function,
                InvocationType='RequestResponse',  # ë™ê¸° í˜¸ì¶œ
                Payload=json.dumps(payload)
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            payload_response = json.loads(response['Payload'].read().decode())
            
            if 'statusCode' in payload_response and payload_response['statusCode'] == 200:
                body = json.loads(payload_response['body'])
                results = body.get('results', [])
                
                # ê²€ìƒ‰ í†µê³„ ì—…ë°ì´íŠ¸
                self.search_stats["total_searches"] += 1
                self.search_stats["successful_searches"] += 1
                self.search_stats["total_documents_found"] += len(results)
                
                # ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
                elapsed_time = time.time() - start_time
                self._update_average_response_time(elapsed_time)
                
                # ìºì‹œ íˆíŠ¸ ì—¬ë¶€
                from_cache = body.get('from_cache', False)
                cache_status = "ìºì‹œ ì‚¬ìš©" if from_cache else "ì‹ ê·œ ê²€ìƒ‰"
                
                # ê²°ê³¼ ë¡œê¹…
                print(f"  âœ… S3 ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ({cache_status}, {elapsed_time:.2f}ì´ˆ)")
                
                # Document ê°ì²´ë¡œ ë³€í™˜
                documents = self._convert_to_documents(results)
                return documents
            else:
                # ì˜¤ë¥˜ ì‘ë‹µ
                error_message = payload_response.get('body', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                print(f"  âŒ S3 ê²€ìƒ‰ ì‹¤íŒ¨: {error_message}")
                
                self.search_stats["total_searches"] += 1
                self.search_stats["failed_searches"] += 1
                
                return []
            
        except Exception as e:
            logger.error(f"S3 ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            print(f"  âŒ S3 ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            
            self.search_stats["total_searches"] += 1
            self.search_stats["failed_searches"] += 1
            
            return []
    
    def _convert_to_documents(self, search_results: List[Dict]) -> List[Document]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        
        for result in search_results:
            # Document ê°ì²´ ìƒì„±
            doc = Document(
                page_content=result.get('text', 'ë‚´ìš© ì—†ìŒ'),
                metadata={
                    'source': f"s3://{self.bucket_name}/{result.get('text_path', '')}",
                    'document_id': result.get('document_id', ''),
                    'chunk_id': result.get('chunk_id', ''),
                    'similarity_score': result.get('similarity', 0.0),
                    'category': result.get('category', 'ì¼ë°˜ì˜í•™'),
                    'page': result.get('page', 0),
                    'source_type': 's3'
                }
            )
            documents.append(doc)
        
        return documents
    
    def _update_average_response_time(self, elapsed_time: float) -> None:
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        current_avg = self.search_stats["average_response_time"]
        successful_searches = self.search_stats["successful_searches"]
        
        if successful_searches <= 1:
            self.search_stats["average_response_time"] = elapsed_time
        else:
            # ì´ë™ í‰ê·  ê³„ì‚°
            new_avg = ((current_avg * (successful_searches - 1)) + elapsed_time) / successful_searches
            self.search_stats["average_response_time"] = new_avg
    
    def set_enabled(self, enabled: bool) -> None:
        """S3 ë¦¬íŠ¸ë¦¬ë²„ í™œì„±í™”/ë¹„í™œì„±í™”"""
        self.enabled = enabled
        status = "í™œì„±í™”" if enabled else "ë¹„í™œì„±í™”"
        print(f"ğŸ”§ S3 ë¦¬íŠ¸ë¦¬ë²„ ìƒíƒœ ë³€ê²½: {status}")
    
    def get_stats(self) -> Dict[str, Any]:
        """S3 ë¦¬íŠ¸ë¦¬ë²„ í†µê³„ ë°˜í™˜"""
        success_rate = 0
        if self.search_stats["total_searches"] > 0:
            success_rate = self.search_stats["successful_searches"] / self.search_stats["total_searches"] * 100
        
        return {
            "retriever_type": "S3Retriever",
            "enabled": self.enabled,
            "bucket": self.bucket_name,
            "search_function": self.search_function,
            "total_searches": self.search_stats["total_searches"],
            "successful_searches": self.search_stats["successful_searches"],
            "failed_searches": self.search_stats["failed_searches"],
            "success_rate": f"{success_rate:.1f}%",
            "total_documents_found": self.search_stats["total_documents_found"],
            "average_response_time": f"{self.search_stats['average_response_time']:.2f}ì´ˆ"
        }