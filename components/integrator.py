# components/integrator.py (ë¦¬íŒ©í† ë§ëœ ë²„ì „)
from typing import Dict, Any, List
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from prompts import system_prompts

class Integrator:
    """ë‹¤ì¤‘ ì†ŒìŠ¤ ì •ë³´ í†µí•© ë‹´ë‹¹ í´ë˜ìŠ¤ (ê°€ì¤‘ì¹˜ ì ìš©)"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        # ì†ŒìŠ¤ë³„ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜
        self.source_weights = {
            "pubmed": 1.0,     # ìµœê³  ì‹ ë¢°ë„ (í•™ìˆ  ë…¼ë¬¸)
            "bedrock_kb": 0.9, # AWS Bedrock KB (ë†’ì€ ì‹ ë¢°ë„)
            "medgemma": 0.9,   # ë†’ì€ ì‹ ë¢°ë„ (ì˜ë£Œ íŠ¹í™” AI)
            "rag": 0.8,        # ë†’ì€ ì‹ ë¢°ë„ (íë ˆì´ì…˜ëœ ë°ì´í„°)
            "web": 0.6         # ì¤‘ê°„ ì‹ ë¢°ë„ (ì›¹ ê²€ìƒ‰)
        }

        self._setup_integration_chain()
    
    def _setup_integration_chain(self):
        """ì •ë³´ í†µí•© ì²´ì¸ ì„¤ì •"""
        # í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  system_prompts ì‚¬ìš©
        # ê°€ì¤‘ì¹˜ ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ì— ì „ë‹¬í•˜ì—¬ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        self.integration_prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompts.format("INTEGRATOR", 
                pubmed_weight=self.source_weights.get("pubmed", 1.0),
                bedrock_weight=self.source_weights.get("bedrock_kb", 0.9),
                rag_weight=self.source_weights.get("rag", 0.8),
                web_weight=self.source_weights.get("web", 0.6),
                medgemma_weight=self.source_weights.get("medgemma", 0.9)
            )),
            ("human", """Question: {question}

        Sources with weights:
        {weighted_content}

        Provide integrated medical answer with clear source citations for each piece of information:"""),
        ])
        
        self.integration_chain = self.integration_prompt | self.llm | StrOutputParser()
    
    def integrate_answers(self, question: str, source_categorized_docs: Dict[str, List[Document]]) -> str:
        """ë‹¤ì¤‘ ì†ŒìŠ¤ ì •ë³´ë¥¼ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ í†µí•©"""
        print("==== [INTEGRATE WITH WEIGHTS] ====")
        
        if not source_categorized_docs:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ê°€ì¤‘ì¹˜ ì ìš©ëœ ë‚´ìš© êµ¬ì„±
        weighted_content = self._build_weighted_content(source_categorized_docs)
        
        try:
            integrated_answer = self.integration_chain.invoke({
                "question": question,
                "weighted_content": weighted_content
            })
            
            # ì¶œì²˜ í‘œê¸° í˜•ì‹ ê°œì„ 
            enhanced_answer = self._enhance_citations(integrated_answer)
            
            print(f"  âœ… ì†ŒìŠ¤ í†µí•© ì™„ë£Œ ({len(source_categorized_docs)}ê°œ ì†ŒìŠ¤)")
            return enhanced_answer
            
        except Exception as e:
            print(f"  âŒ í†µí•© ì‹¤íŒ¨: {str(e)}")
            return self._fallback_integration(source_categorized_docs)

    def _enhance_citations(self, answer: str) -> str:
        """ì¶œì²˜ í‘œê¸° í˜•ì‹ ê°œì„ """
        import re
        
        # ì¶œì²˜ í‘œê¸° ê°•ì¡° ë° ì¼ê´€ì„± ìœ ì§€
        # [SOURCE_TYPE: specific source] í˜•ì‹ì„ ì¼ê´€ë˜ê²Œ ë³€í™˜
        
        # ì •ê·œì‹ íŒ¨í„´
        citation_pattern = r'\[((?:PubMed|Web|Bedrock_KB|RAG|S3|MedGemma)[^]]*)\]'
        
        # ì¶œì²˜ í‘œê¸° ê°•ì¡°
        def citation_replacer(match):
            citation = match.group(1)
            return f'ã€{citation}ã€‘'
        
        # ì •ê·œì‹ìœ¼ë¡œ ì¶œì²˜ í‘œê¸° ë³€í™˜
        enhanced = re.sub(citation_pattern, citation_replacer, answer)
        
        # ì¶œì²˜ê°€ ì—†ëŠ” ë¬¸ì¥ì— ëŒ€í•œ ì•ˆë‚´ ì¶”ê°€
        if 'ã€' not in enhanced:
            enhanced += "\n\n(âš ï¸ ì°¸ê³ : ì´ ë‹µë³€ì€ ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë‚˜, êµ¬ì²´ì ì¸ ì¶œì²˜ë¥¼ í‘œê¸°í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì •í™•í•œ ì˜ë£Œ ì •ë³´ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.)"
        
        return enhanced
    
    def _build_weighted_content(self, categorized_docs: Dict[str, List[Document]]) -> str:
        """ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ë‚´ìš© êµ¬ì„±"""
        content_parts = []
        
        for source_type, docs in categorized_docs.items():
            if not docs:
                continue
                
            weight = self.source_weights.get(source_type, 0.5)
            
            content_parts.append(f"\n=== {source_type.upper()} SOURCES (ì‹ ë¢°ë„: {weight}) ===")
            
            for i, doc in enumerate(docs):
                # ì†ŒìŠ¤ ìœ í˜•ë³„ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
                source_info = self._extract_source_info(source_type, doc)
                content = doc.page_content[:300]  # 300ì ì œí•œ
                
                # ì¶œì²˜ ì •ë³´ í¬í•¨
                content_parts.append(f"{i+1}. [{source_info}] {content}")
        
        return "\n".join(content_parts)

    def _extract_source_info(self, source_type: str, doc: Document) -> str:
        """ë¬¸ì„œ ìœ í˜•ë³„ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ"""
        metadata = doc.metadata or {}
        
        if source_type == "pubmed":
            # PubMed ë…¼ë¬¸ ì •ë³´
            authors = metadata.get("authors", [])
            author_text = f"{authors[0]} ì™¸" if authors and len(authors) > 1 else ", ".join(authors) if authors else "Unknown"
            year = metadata.get("year", "")
            journal = metadata.get("journal", "")
            return f"PubMed: {author_text} ({year}), {journal}"
        
        elif source_type == "web":
            # ì›¹ ì¶œì²˜ ì •ë³´
            source = metadata.get("source", "")
            # URLì—ì„œ ë„ë©”ì¸ë§Œ ì¶”ì¶œ
            import re
            domain = ""
            if isinstance(source, str) and "://" in source:
                match = re.search(r'://([^/]+)', source)
                if match:
                    domain = match.group(1)
                    # www. ì œê±°
                    domain = re.sub(r'^www\.', '', domain)
            
            return f"Web: {domain or source or 'Unknown website'}"
        
        elif source_type == "bedrock_kb":
            # Bedrock KB ë¬¸ì„œ ì •ë³´ - ë” êµ¬ì²´ì ì¸ ì •ë³´
            title = metadata.get("title", "")
            doc_id = metadata.get("document_id", "")
            category = metadata.get("category", "")
            
            # Documentë§Œ í‘œì‹œë˜ëŠ” ê²½ìš° ë‚´ìš©ì—ì„œ ì œëª© ì¶”ì¶œ ì‹œë„
            if not title and not doc_id:
                content = doc.page_content or ""
                # ì²« ì¤„ì´ë‚˜ ì²« 10ë‹¨ì–´ë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                first_line = content.split('\n')[0] if '\n' in content else ""
                content_preview = first_line[:50] if first_line else " ".join(content.split()[:7])
                
                if content_preview:
                    return f"Bedrock KB: {content_preview}..."
            
            return f"Bedrock KB: {title or doc_id or category or 'Medical document'}"
        
        elif source_type == "s3":
            # S3 ë¬¸ì„œ ì •ë³´
            path = metadata.get("source", "")
            title = metadata.get("title", "")
            # ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            if isinstance(path, str):
                import os
                filename = os.path.basename(path)
            else:
                filename = ""
            
            return f"S3: {title or filename or 'Document'}"
        
        elif source_type == "rag":
            # ë‚´ë¶€ RAG ë¬¸ì„œ ì •ë³´
            source = metadata.get("source", "")
            title = metadata.get("title", "")
            category = metadata.get("category", "")
            
            # ì†ŒìŠ¤ì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            if isinstance(source, str):
                import os
                filename = os.path.basename(source)
            else:
                filename = ""
            
            return f"RAG: {title or filename or category or 'Document'}"
        
        elif source_type == "medgemma":
            # MedGemma ì •ë³´
            model = metadata.get("model_name", "MedGemma")
            return f"MedGemma: {model}"
        
        # ê¸°ë³¸ ì¶œì²˜ ì •ë³´
        return f"{source_type}: {metadata.get('source', 'Unknown')}"
    
    def _fallback_integration(self, categorized_docs: Dict[str, List[Document]]) -> str:
        """í†µí•© ì‹¤íŒ¨ ì‹œ í´ë°± ë°©ë²•"""
        print("  ğŸ”„ ê¸°ë³¸ í†µí•© ë°©ì‹ ì‚¬ìš©")
        
        # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤ë¶€í„° ì‚¬ìš©
        for source_type in ["pubmed", "medgemma", "rag"]:
            if source_type in categorized_docs and categorized_docs[source_type]:
                docs = categorized_docs[source_type]
                weight = self.source_weights[source_type]
                
                return f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤ (ì‹ ë¢°ë„: {weight}):

{docs[0].page_content[:500]}

ì´ ì •ë³´ëŠ” {source_type} ì†ŒìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì…ë‹ˆë‹¤. 
ì •í™•í•œ ì˜ë£Œ ì •ë³´ë¥¼ ìœ„í•´ì„œëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."